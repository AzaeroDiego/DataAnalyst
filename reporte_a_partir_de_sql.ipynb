{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import pandas as pd\n",
    "import locale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine, text\n",
    "from dateutil.parser import parse\n",
    "import gender_guesser.detector as gender\n",
    "import warnings\n",
    "\n",
    "# Suprimir las advertencias de tipo FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Configurar locale para español (Perú)\n",
    "locale.setlocale(locale.LC_TIME, 'es_PE.UTF-8')\n",
    "\n",
    "# Variables PERIODO ABRIL 2024\n",
    "fecha = '202409'\n",
    "# Mes a partir del fecha\n",
    "mes = dt.datetime.strptime(fecha, '%Y%m').strftime('%B').upper()\n",
    "usuario = 'azaer'\n",
    "Ruta = rf'C:\\Users\\{usuario}\\Documents\\Diego\\Reportes'\n",
    "hoy = dt.datetime.now().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parámetros de conexión\n",
    "server = r'server'\n",
    "database = 'database'\n",
    "schema = 'dbo'\n",
    "username = 'usuario'\n",
    "password = 'password'\n",
    "connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};'\n",
    "\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(f'mssql+pyodbc://sa:sanandreas666@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "\n",
    "# Crear la conexión\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "# Definir la consulta SQL\n",
    "query = text(f\"\"\"\n",
    "Select * From Reportes_Chubb..clientes where aniomes = '{fecha}'\n",
    "\"\"\")\n",
    "\n",
    "query1 = text(f\"\"\"\n",
    "SELECT * FROM Reportes_Chubb..adicionales where feC_VENTA like '{fecha}%'\n",
    "\"\"\")\n",
    "\n",
    "# Ejecutar la consulta y leer los datos en un DataFrame de pandas\n",
    "with engine.connect() as connection:\n",
    "    df_clientes = pd.read_sql((query), connection)\n",
    "    df_adicionales = pd.read_sql((query1), connection)\n",
    "\n",
    "\n",
    "# Reemplazar None (valores nulos) por una cadena vacía\n",
    "df_clientes = df_clientes.fillna('')\n",
    "df_adicionales = df_adicionales.fillna('')\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    try:\n",
    "        # Intentar convertir las fechas en formato \"YYYY-MM-DD\"\n",
    "        return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Intentar convertir las fechas en formato \"YYYYMMDD\"\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d', errors='coerce')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "    \n",
    "df_adicionales['feC_NACIMIENTO'] = df_adicionales['feC_NACIMIENTO'].apply(normalize_date).dt.strftime('%d/%m/%Y')\n",
    "df_clientes['fechanacimiento'] = df_clientes['fechanacimiento'].apply(normalize_date).dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaer\\AppData\\Local\\Temp\\ipykernel_34460\\4236202358.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'HORA MEJOR GESTIÓN' : pd.to_datetime(df_resultante['hora'], errors='coerce').dt.strftime('%H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas en Resultante igual a: 270 \n"
     ]
    }
   ],
   "source": [
    "# Reporte de Resultante\n",
    "\n",
    "df_resultante = df_clientes.copy() \n",
    "\n",
    "df_resultante = pd.DataFrame({\n",
    "    'DNI' : df_resultante['dni'].str[-8:],\n",
    "    'INTENTOS CONTACTO' :  pd.to_numeric(df_resultante['intentoS_MEDIATEL'], errors='coerce').fillna(0).astype('int64'),\n",
    "    'FECHA MEJOR GESTIÓN' : pd.to_datetime(df_resultante['fecha'], errors='coerce').dt.strftime('%d/%m/%Y'),\n",
    "    'HORA MEJOR GESTIÓN' : pd.to_datetime(df_resultante['hora'], errors='coerce').dt.strftime('%H:%M:%S'),\n",
    "    'CALL' : 'CALLSOUTH PERU',\n",
    "     'ESTADO' : df_resultante['niveL_3'].apply(lambda x: 'A' if x == 'VOLVER A LLAMAR' else 'T'),\n",
    "    'MOTIVO' : df_resultante['niveL_3'],\n",
    "    'NOMBRE DE BBDD' : df_resultante['campana'].map(lambda x: 'RIPLEY PROTECCIÓN ACCIDENTAL' if 'ACCIDENTES_PERSONALES' in x or 'CHUBB_AP_P' in x else\n",
    "                                                  ('RIPLEY SONRIE SEGURO' if 'SONRIE_SEGURO' in x or 'CHUBB_SONRIE_SEGURO_P' in x else 'RIPLEY CAMINA SEGURO')) + '-' + df_resultante['captación'].str.upper() + '-' + mes,\n",
    "    'CODIGO DEL EJECUTIVO' : '',\n",
    "    'NOMBRE DEL EJECUTIVO' : df_resultante['agente'],\n",
    "    'TipoContrato' : df_resultante['tipoContrato'],\n",
    "    'Cel 1' : df_resultante['ceL1'],\n",
    "    'Cel 2' : df_resultante['ceL2']       })\n",
    "\n",
    "# Filtrar si Motivo es vacio\n",
    "df_resultante = df_resultante[df_resultante['MOTIVO'] != '']\n",
    "\n",
    "\n",
    "# Crear una columna que indica cuántas veces se debe duplicar cada fila\n",
    "df_resultante['Duplicar'] = 1  # Por defecto no duplicar\n",
    "\n",
    "df_resultante.loc[df_resultante['TipoContrato'].str.contains(r'1', regex=True), 'Duplicar'] = 2\n",
    "df_resultante.loc[df_resultante['TipoContrato'].str.contains(r'2', regex=True), 'Duplicar'] = 3\n",
    "df_resultante.loc[df_resultante['TipoContrato'].str.contains(r'3', regex=True), 'Duplicar'] = 4\n",
    "\n",
    "# Duplicar las filas según el valor en la columna 'Duplicar'\n",
    "df_resultante = df_resultante.loc[np.repeat(df_resultante.index.values, df_resultante['Duplicar'])]\n",
    "\n",
    "# Eliminar la columna 'Duplicar'\n",
    "df_resultante = df_resultante.drop(columns=['Duplicar'])\n",
    "\n",
    "\n",
    "# Homologar columna Motivo \n",
    "df_resultante['MOTIVO'] = df_resultante['MOTIVO'].replace({\n",
    "    'VENTA': 'Venta',\n",
    "    'CLIENTE CORTO LLAMADA CON INFO': 'No desea Cliente no escucha propuesta',\n",
    "    'REVALIDACION': 'No desea Solicita información adicional',\n",
    "    'ND LO LLAMARON MAS DE UNA VEZ': 'No desea Oferta - No le interesa',\n",
    "    'ND NO TIENE TARJETA': 'No califica - Canceló tarjeta',\n",
    "    'NO DESEA - YA LE OFRECIERON': 'No desea Oferta - No le interesa',\n",
    "    'ND COYUNTURAL': 'No desea No necesita',\n",
    "    'ND POR COSTO': 'No desea Tema del Cliente Económico',\n",
    "    'ND NO CONTRATA NADA POR TELF.': 'NO VOLVER A LLAMAR Protección de datos',\n",
    "    'VOLVER A LLAMAR': 'Agendado a solicitud del titular - Mañana',\n",
    "    'ND NO BRINDA MOTIVO' : 'No desea Cliente corto llamada',\n",
    "    'ND NO CONFORME RIPLEY' : 'No desea - insatisfecho con Ripley',\n",
    "    'CONTACTO CON TERCERO' : 'Agendado por no encontrar al titular -  Mañana',\n",
    "    'CORTA LLAMADA SIN INFO' : 'Agendado por no encontrar al titular -  Mañana',\n",
    "    'NUMERO EQUIVOCADO' : 'No corresponde',\n",
    "    'TITULAR INUBICABLE' : 'Contacto con Terceros día',\n",
    "    'NO CONTESTA / OCUPADO' : 'No contesta día',\n",
    "    'GRABADORA' : 'Grabadora',\n",
    "    'BUZON DE VOZ' : 'Grabadora',\n",
    "    'FUERA DE SERVICIO / SUSPENDIDO' : 'Fuera de Servicio, malogrado, línea saturada',\n",
    "    'NO CONTACTADOS' : 'No contesta día',\n",
    "    'NO CONTESTA' : 'No contesta día',\n",
    "    'NO CORRESPONDE' :  'No corresponde'\n",
    "}) \n",
    "\n",
    "# Ordenar columna por Fecha mejor gestion y hora mejor gestion\n",
    "df_resultante = df_resultante.sort_values(by=['FECHA MEJOR GESTIÓN', 'HORA MEJOR GESTIÓN'], ascending=[True, True])\n",
    "\n",
    "# Calcular el Numero de Ventas en resultante\n",
    "Ventas_resultantes =len(df_resultante[df_resultante['MOTIVO'] == 'Venta'])\n",
    "\n",
    "print(f'Ventas en Resultante igual a: {Ventas_resultantes} ')   \n",
    "\n",
    "# Eliminar columnas innecesarias (TipoContrato, Cel 1, Cel 2)\n",
    "df_resultante = df_resultante.drop(columns=['TipoContrato', 'Cel 1', 'Cel 2'])\n",
    "\n",
    "\n",
    "# Guardar el dataframe en un archivo excel\n",
    "df_resultante.to_excel(f'{Ruta}\\\\Resultantes\\\\Reporte_Resultante_{fecha}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte Validación generado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaer\\AppData\\Local\\Temp\\ipykernel_34460\\3230604148.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'HORA DE VENTA' : pd.to_datetime(df_validacion['horavta'], errors='coerce').dt.strftime('%H:%M:%S'),\n"
     ]
    }
   ],
   "source": [
    "# Reporte de Validacion de Ventas\n",
    "\n",
    "df_validacion = df_clientes.copy()\n",
    "\n",
    "# Filtrar solo las ventas\n",
    "df_validacion = df_validacion[df_validacion['niveL_3'] == 'VENTA']\n",
    "\n",
    "df_validacion = pd.DataFrame({\n",
    "    'DNI' : df_validacion['dni'].str[-8:],\n",
    "    'FECHA DE VENTA' : pd.to_datetime(df_validacion['fechavta'], errors='coerce').dt.strftime('%d/%m/%Y'),\n",
    "    'HORA DE VENTA' : pd.to_datetime(df_validacion['horavta'], errors='coerce').dt.strftime('%H:%M:%S'),\n",
    "    'NOMBRE CLIENTE' : df_validacion['nombre'],\n",
    "    'NOMBRE EJECUTIVO' : df_validacion['agente'],\n",
    "    'NOMBRE PRODUCTO' : df_validacion['campana'].map(lambda x: 'RIPLEY PROTECCIÓN ACCIDENTAL' if 'ACCIDENTES_PERSONALES' in x or 'CHUBB_AP_P' in x else\n",
    "                                                  ('RIPLEY SONRIE SEGURO' if 'SONRIE_SEGURO' in x or 'CHUBB_SONRIE_SEGURO_P' in x else 'RIPLEY CAMINA SEGURO')),\n",
    "    'PRIMER ESTADO AUDITORIA' : df_validacion['primeR_ESTADO_CALIDAD'],\n",
    "    'PRIMER MOTIVO AUDITORIA' : df_validacion['primeR_MOTIVO_CALIDAD'],\n",
    "    'PRIMER FECHA AUDITORIA' : pd.to_datetime(df_validacion['primeR_FECHA_CALIDAD'], errors='coerce').dt.strftime('%d/%m/%Y'),\n",
    "    'SEGUNDO ESTADO AUDITORIA' : df_validacion['segundO_ESTADO_CALIDAD'],\n",
    "    'SEGUNDO MOTIVO AUDITORIA' : df_validacion['segundO_MOTIVO_CALIDAD'],\n",
    "    'SEGUNDO FECHA AUDITORIA' : pd.to_datetime(df_validacion['segundO_FECHA_CALIDAD'], errors='coerce').dt.strftime('%d/%m/%Y'),\n",
    "    'NOMBRE CALL CENTER' : 'CALLSOUTH PERU',\n",
    "    'ANIO' : df_validacion['aniomes'].str[:4],\n",
    "    'MES' : df_validacion['aniomes'].str[4:6],\n",
    "    'CALIDAD FINAL' : df_validacion['nuevo_Estado_Calidad'],\n",
    "    'Ventas_Adiciones' : df_validacion['tipoContrato'].map(\n",
    "    lambda x: 2 if pd.notnull(x) and '1' in x else\n",
    "              3 if pd.notnull(x) and '2' in x else\n",
    "              4 if pd.notnull(x) and '3' in x else\n",
    "              1 if pd.notnull(x) and 'titular' in x.lower() and 'adicional' not in x.lower() else\n",
    "              0\n",
    ")})\n",
    "\n",
    "# Guardar el dataframe en un archivo excel\n",
    "df_validacion.to_excel(f'{Ruta}\\\\Validacion\\\\Reporte_Validacion_{fecha}.xlsx', index=False)\n",
    "\n",
    "print('Reporte Validación generado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al conectar con https://app.soluziona.pe/API_QA/Peru/CRM/api/Excel_CRM/CRM/Reporte/Conexiones/Excel/202409/1. Creando DataFrame vacío.\n",
      "Error al conectar con https://app.soluziona.pe/API_QA/Peru/CRM/api/Excel_CRM/CRM/Reporte/Conexiones/Excel/202409/2. Creando DataFrame vacío.\n",
      "Error al conectar con https://app.soluziona.pe/API_QA/Peru/CRM/api/Excel_CRM/CRM/Reporte/Conexiones/Excel/202409/3. Creando DataFrame vacío.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaer\\AppData\\Local\\Temp\\ipykernel_34460\\2964783206.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  'hora' : pd.to_datetime(df_sumarizado['hora'], errors='coerce').dt.strftime('%H'),\n"
     ]
    }
   ],
   "source": [
    "# Reporte de Sumarizado a partir de df_cliente\n",
    "\n",
    "df_sumarizado = df_clientes.copy()\n",
    "\n",
    "# Consolidar las 3 compañías y emitir informe\n",
    "company_ids = [1, 2, 3]\n",
    "company_names = {\n",
    "    1: 'SONRIE_SEGURO',\n",
    "    2: 'ACCIDENTES_PERSONALES',\n",
    "    3: 'CAMINA_SEGURO'\n",
    "}\n",
    "df_ocupacion = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre las compañías Ocupacion\n",
    "for company in company_ids:\n",
    "    url = f'https://app.soluziona.pe/API_QA/Peru/CRM/api/Excel_CRM/CRM/Reporte/Conexiones/Excel/{fecha}/{company}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url,timeout=10)\n",
    "        response.raise_for_status()  # Verificar si hubo un error en la solicitud\n",
    "        data = response.json()\n",
    "        company_df = pd.DataFrame(data)\n",
    "        company_df['campaña'] = company_names[company]  # Añadir la columna 'campaña'\n",
    "\n",
    "    except:\n",
    "        # Si ocurre cualquier error, crea un DataFrame vacío\n",
    "        print(f\"Error al conectar con {url}. Creando DataFrame vacío.\")\n",
    "        company_df = pd.DataFrame()\n",
    "\n",
    "    # Concatenar el DataFrame de la compañía actual al DataFrame principal\n",
    "    df_ocupacion = pd.concat([df_ocupacion, company_df], ignore_index=True)\n",
    "\n",
    "#Crear un DataFrame con las columnas necesarias\n",
    "sumarizado = pd.DataFrame({\n",
    "    'numero_documento' : df_sumarizado['dni'].str[-8:],\n",
    "    'dia' : pd.to_datetime(df_sumarizado['fecha'], errors='coerce').dt.strftime('%d'),\n",
    "    'semana' : pd.to_datetime(df_sumarizado['fecha'], errors='coerce').dt.strftime('%W'),\n",
    "    'hora' : pd.to_datetime(df_sumarizado['hora'], errors='coerce').dt.strftime('%H'),\n",
    "    'nivel_1' : df_sumarizado['niveL_1'],\n",
    "    'nivel_2' : df_sumarizado['niveL_2'],\n",
    "    'nivel_3' : df_sumarizado['niveL_3'],\n",
    "    'tipo_captacion' : df_sumarizado['captación'],\n",
    "    'nombre' : df_sumarizado['agente'],\n",
    "    'tmo' : pd.to_timedelta(df_sumarizado['tmo'], errors='coerce').fillna('00:00:00').dt.total_seconds().astype(int),\n",
    "    'cargado' : 1,\n",
    "    'tramitado' : df_sumarizado['Tramitado'],\n",
    "    'contacto' : df_sumarizado['Contacto'],\n",
    "    'No contacto': np.where(df_sumarizado['Tramitado'] == 1,np.where(df_sumarizado['Contacto'] == 1, 0, 1), 0),\n",
    "    'valido' :  df_sumarizado['Valido'],\n",
    "    'no valido' : np.where(df_sumarizado['Tramitado'] == 1,np.where(df_sumarizado['Valido'] == 1, 0, 1), 0),\n",
    "    'ventas' : df_sumarizado['Ventas'],\n",
    "    'Ventas_Adicionales' : df_sumarizado['tipoContrato'].map(\n",
    "    lambda x: 2 if pd.notnull(x) and '1' in x else\n",
    "              3 if pd.notnull(x) and '2' in x else\n",
    "              4 if pd.notnull(x) and '3' in x else\n",
    "              1 if pd.notnull(x) and 'titular' in x.lower() and 'adicional' not in x.lower() else\n",
    "              0),\n",
    "    'TipoContrato' : df_sumarizado['tipoContrato'],\n",
    "    'Marcaciones' : '',\n",
    "    'MarcacionesMediatel' : pd.to_numeric(df_sumarizado['intentoS_MEDIATEL'], errors='coerce').fillna(0).astype('int64'),\n",
    "    'calidad_Estado' : df_sumarizado['nuevo_Estado_Calidad'],\n",
    "    'Campaña' : df_sumarizado['campana']})\n",
    "\n",
    "# Verificar si la ruta existe y si no, crearla\n",
    "if not os.path.exists(os.path.join(Ruta,'Sumarizados',f\"{fecha}\")):\n",
    "    os.makedirs(os.path.join(Ruta,'Sumarizados',f\"{fecha}\"))\n",
    "\n",
    "# Guardar el consolidado en la carpeta de destino y guardar df y df_ocupacion en diferentes hojas\n",
    "ruta_consolidado = os.path.join(Ruta,'Sumarizados',f\"{fecha}\", f\"Sumarizado_{fecha}.xlsx\")\n",
    "with pd.ExcelWriter(ruta_consolidado) as writer:\n",
    "    sumarizado.to_excel(writer, sheet_name='Sumarizado', index=False)\n",
    "    df_ocupacion.to_excel(writer, sheet_name='Ocupacion', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Último código utilizado: 20868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaer\\AppData\\Local\\Temp\\ipykernel_34460\\2635938460.py:340: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  trama_completa = trama_completa.groupby(['CODIGO_CLIENTE', 'grupo'], group_keys=False).apply(lambda g: g.replace('', np.nan).ffill())\n",
      "C:\\Users\\azaer\\AppData\\Local\\Temp\\ipykernel_34460\\2635938460.py:350: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  observaciones_por_grupo = trama_completa.groupby('NRO_UNICO_CARGA').apply(generar_observaciones).reset_index()\n"
     ]
    }
   ],
   "source": [
    "df_trama = df_clientes.copy()\n",
    "\n",
    "def separar_nombre(nombre_completo):\n",
    "    # Dividir el nombre completo en partes usando los espacios\n",
    "    partes = nombre_completo.split()\n",
    "\n",
    "    # Inicializar las variables\n",
    "    apellido_paterno = ''\n",
    "    apellido_materno = ''\n",
    "    nombre1 = ''\n",
    "    nombre2 = ''\n",
    "\n",
    "    # Asignar valores basados en el número de partes\n",
    "    if len(partes) > 4:\n",
    "        # Considerar el caso de más de 4 partes\n",
    "        apellido_materno = partes[-1]\n",
    "        apellido_paterno = partes[-2]\n",
    "        nombre1 = partes[0]\n",
    "        nombre2 = ' '.join(partes[1:-2])\n",
    "    elif len(partes) == 4:\n",
    "        nombre1, nombre2, apellido_paterno, apellido_materno = partes\n",
    "    elif len(partes) == 3:\n",
    "        nombre1, apellido_paterno, apellido_materno = partes\n",
    "    elif len(partes) == 2:\n",
    "        nombre1, apellido_paterno = partes\n",
    "    elif len(partes) == 1:\n",
    "        nombre1 = partes[0]\n",
    "\n",
    "    return apellido_paterno, apellido_materno, nombre1, nombre2\n",
    "\n",
    "mes = dt.datetime.strptime(fecha, '%Y%m').strftime('%B')\n",
    "\n",
    "nombres_separados = df_trama['nombre'].apply(separar_nombre).apply(pd.Series)\n",
    "nombres_separados.columns = ['apellido_paterno', 'apellido_materno', 'nombre1', 'nombre2']\n",
    "df_trama = pd.concat([df_trama, nombres_separados], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#Filtrar solo las ventas en estado S y NS en columna nuevo_Estado_Calidad\n",
    "df_trama = df_trama[(df_trama['nuevo_Estado_Calidad'] == 'S') | (df_trama['nuevo_Estado_Calidad'] == 'NS')]\n",
    "\n",
    "\n",
    "#Importar Tabla de Ubicacion para reemplazar códigos\n",
    "archivo_codigos = rf'C:\\Users\\{usuario}\\Documents\\Diego\\Reportes\\TRAMAS\\Tabla de Códigos Trama.xlsx'\n",
    "df_codigos = pd.read_excel(archivo_codigos, sheet_name='Tabla 2 Datos vivienda' , dtype=str)\n",
    "\n",
    "#Reemplazar en df_trama si departamento, provincia y distrito es piura, piura, 0 por piura, piura, piura , solo si se cumple la condición\n",
    "df_trama.loc[(df_trama['departamento'] == 'piura') & (df_trama['provincia'] == 'piura') & (df_trama['distrito'] == '0'), 'distrito'] = 'piura'\n",
    "\n",
    "# Concatenar en la tabla de clientes\n",
    "df_trama['concat'] = df_trama['departamento']+ df_trama['provincia']+ df_trama['distrito']\n",
    "\n",
    "df_trama = df_trama.merge(df_codigos[['J', 'UBIGEO']], left_on='concat', right_on='J', how='left')\n",
    "\n",
    "df_trama['DEPARTAMENTO_ID'] = df_trama['UBIGEO'].str[:2]\n",
    "df_trama['PROVINCIA_ID'] = df_trama['UBIGEO'].str[2:4]\n",
    "df_trama['DISTRITO_ID'] = df_trama['UBIGEO'].str[4:]\n",
    "\n",
    "mapeo_avanzado = {\n",
    "    'CONYUGE': {'parentescO_ID': '38', 'tipO_ASEG': 'AC'},\n",
    "    'HIJO': {'parentescO_ID': '39', 'tipO_ASEG': 'AH'},\n",
    "    'HERMANO': {'parentescO_ID': '40', 'tipO_ASEG': 'AO'},\n",
    "    'PADRE': {'parentescO_ID': '42', 'tipO_ASEG': 'AO'},\n",
    "    'MADRE': {'parentescO_ID': '43', 'tipO_ASEG': 'AO'},\n",
    "    'OTRO FAMILIAR': {'parentescO_ID': '44', 'tipO_ASEG': 'AO'},\n",
    "    'OTRA RELACION': {'parentescO_ID': '45', 'tipO_ASEG': 'AO'},\n",
    "    'HIJA': {'parentescO_ID': '1347', 'tipO_ASEG': 'AH'},\n",
    "    'HERMANA': {'parentescO_ID': '1348', 'tipO_ASEG': 'AO'},\n",
    "    'SOBRINO': {'parentescO_ID': '1349', 'tipO_ASEG': 'AO'},\n",
    "    'SOBRINA': {'parentescO_ID': '1352', 'tipO_ASEG': 'AO'}\n",
    "}\n",
    "\n",
    "# Crear un detector de género\n",
    "d = gender.Detector()\n",
    "\n",
    "def asignar_prima(tipo_contrato):\n",
    "    if pd.notnull(tipo_contrato):\n",
    "        tipo_contrato = tipo_contrato.lower()\n",
    "        if '1' in tipo_contrato:\n",
    "            return '44.9'\n",
    "        elif '2' in tipo_contrato or '3' in tipo_contrato:\n",
    "            return '59.9'\n",
    "        elif 'titular' in tipo_contrato and 'adicional' not in tipo_contrato:\n",
    "            return '29.9'\n",
    "    return '0'\n",
    "\n",
    "def asignar_producto(campana):\n",
    "    if pd.notnull(campana):\n",
    "        if 'ACCIDENTES_PERSONALES' in campana or 'CHUBB_AP_P' in campana:\n",
    "            return 'RIPLEY PROTECCIÓN ACCIDENTAL'\n",
    "        elif 'SONRIE_SEGURO' in campana or 'CHUBB_SONRIE_SEGURO_P' in campana:\n",
    "            return 'RIPLEY SONRIE SEGURO'\n",
    "    return 'RIPLEY CAMINA SEGURO'\n",
    "\n",
    "def asignar_producto_id(campana):\n",
    "    if pd.notnull(campana):\n",
    "        if 'ACCIDENTES_PERSONALES' in campana or 'CHUBB_AP_P' in campana:\n",
    "            return '95'\n",
    "        elif 'SONRIE_SEGURO' in campana or 'CHUBB_SONRIE_SEGURO_P' in campana:\n",
    "            return '94'\n",
    "    return '96'\n",
    "\n",
    "def asignar_plan_id(tipo_contrato, campana):\n",
    "    if pd.notnull(campana):\n",
    "        campana = campana.upper()\n",
    "        tipo_contrato = tipo_contrato.lower() if pd.notnull(tipo_contrato) else \"\"\n",
    "\n",
    "        if 'CAMINA' in campana:\n",
    "            return '216'\n",
    "        elif 'AP' in campana or 'ACCIDENTES_PERSONALES' in campana:\n",
    "            return '215'\n",
    "        elif 'SONRIE' in campana:\n",
    "            if 'titular' in tipo_contrato:\n",
    "                if '1' in tipo_contrato:\n",
    "                    return '223'\n",
    "                elif '2' in tipo_contrato:\n",
    "                    return '228'\n",
    "                elif '3' in tipo_contrato:\n",
    "                    return '224'\n",
    "                else:\n",
    "                    return '214'\n",
    "        elif 'PROTECCIÓN ACCIDENTAL' in campana:\n",
    "            return '215'\n",
    "    return 'ERROR'\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    try:\n",
    "        # Intentar convertir las fechas en formato \"YYYY-MM-DD\"\n",
    "        return pd.to_datetime(date_str, format='%Y%m%d', errors='coerce')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Intentar convertir las fechas en formato \"YYYYMMDD\"\n",
    "        return pd.to_datetime(date_str, format='%Y-%m-%d', errors='coerce')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "    \n",
    "def mapear_parentesco_id(descripcion):\n",
    "    descripcion = descripcion.strip().upper()\n",
    "    return mapeo_avanzado.get(descripcion, {'parentescO_ID': '45'})['parentescO_ID']\n",
    "\n",
    "def mapear_tipo_aseg(descripcion):\n",
    "    descripcion = descripcion.strip().upper()\n",
    "    return mapeo_avanzado.get(descripcion, {'tipO_ASEG': 'AO'})['tipO_ASEG']\n",
    "\n",
    "def get_gender(nombre):\n",
    "    return d.get_gender(nombre)\n",
    "\n",
    "def generar_observaciones(grupo):\n",
    "    observaciones = []\n",
    "    \n",
    "    # Condiciones generales\n",
    "    if 'AT' not in grupo['TIPO_ASEG'].values:\n",
    "        observaciones.append(\"No hay Titular en el Grupo Familiar\")\n",
    "    \n",
    "    titular = grupo[grupo['TIPO_ASEG'] == 'AT'].iloc[0] if 'AT' in grupo['TIPO_ASEG'].values else None\n",
    "    \n",
    "    # Condiciones para un solo miembro en el grupo\n",
    "    if len(grupo) == 1:\n",
    "        if titular is not None:\n",
    "            if titular['PRIMA'] != '29.9':\n",
    "                observaciones.append(\"Prima no corresponde\")\n",
    "            if titular['PRODUCTO'] == 'RIPLEY SONRIE SEGURO' and titular['PRODUCTO_ID'] != '94':\n",
    "                observaciones.append(\"Producto ID no corresponde\")\n",
    "    else:\n",
    "        # Más de un miembro en el grupo\n",
    "        if titular is not None:\n",
    "            if titular['PRODUCTO'] != 'RIPLEY SONRIE SEGURO':\n",
    "                observaciones.append(\"Más de 1 Titular para plan que no corresponde\")\n",
    "        \n",
    "        # Condiciones para dos miembros en el grupo\n",
    "        if len(grupo) == 2: \n",
    "            if any(grupo['PLAN_ID'] != '223'):\n",
    "                observaciones.append(\"Error plan ID\")\n",
    "\n",
    "        # Condiciones para tres o cuatro miembros en el grupo\n",
    "        if len(grupo) == 3:\n",
    "            if any(grupo['PLAN_ID'] != '228'):\n",
    "                observaciones.append(\"Error plan ID\")\n",
    "        \n",
    "        # Condiciones para tres o cuatro miembros en el grupo\n",
    "        if len(grupo) == 4:\n",
    "            if any(grupo['PLAN_ID'] != '224'):\n",
    "                observaciones.append(\"Error plan ID\")\n",
    "        if len(grupo) > 4 :\n",
    "            observaciones.append(\"Más de 4 miembros en el grupo\")\n",
    "\n",
    "        # Condición para más de un miembro y producto ID diferente de 94\n",
    "        if any(grupo['PRODUCTO_ID'] != '94'):\n",
    "            observaciones.append(\"Error producto ID\")\n",
    "    \n",
    "    # Errores de ubicación\n",
    "    if any(grupo['DEPARTAMENTO'] == '00'):\n",
    "        observaciones.append(\"Error en departamento\")\n",
    "    if any(grupo['PROVINCIA'] == '00'):\n",
    "        observaciones.append(\"Error en provincia\")\n",
    "    if any(grupo['DISTRITO'] == '00'):\n",
    "        observaciones.append(\"Error en distrito\")\n",
    "    \n",
    "    # Error de longitud del DNI\n",
    "    if any(grupo['NRO_DOC'].str.len() != 8) or any(~grupo['NRO_DOC'].str.isnumeric()):\n",
    "        observaciones.append(\"Error longitud DNI\")\n",
    "    \n",
    "    return \", \".join(observaciones)\n",
    "\n",
    "\n",
    "# aplicar las funciones \n",
    "\n",
    "df_trama['PRIMA'] = df_trama['tipoContrato'].apply(asignar_prima)\n",
    "df_trama['PRODUCTO'] = df_trama['campana'].apply(asignar_producto)\n",
    "df_trama['PRODUCT_ID'] = df_trama['campana'].apply(asignar_producto_id)\n",
    "df_trama['PLAN_ID'] = df_trama.apply(lambda x: asignar_plan_id(x['tipoContrato'], x['campana']), axis=1)\n",
    "\n",
    "#Filtrar DNIS que no estan en el archivo total\n",
    "archivo_total = rf'C:\\Users\\{usuario}\\Documents\\Diego\\Reportes\\TRAMAS\\Acumulado Traza Total.xlsx'\n",
    "df_total = pd.read_excel(archivo_total, sheet_name=f'{mes}' , dtype=str)\n",
    "df_trama = df_trama[~df_trama['dni'].isin(df_total['NRO_DOC'])]\n",
    "\n",
    "#Obtener el último código utilizado\n",
    "ultimo_codigo = int(df_total['NRO_UNICO_CARGA'].max())\n",
    "print(\"Último código utilizado:\", ultimo_codigo)\n",
    "\n",
    "#Filtrar Adicionales que tengan el mismo cli_id de df_trama\n",
    "df_adicionales = df_adicionales[df_adicionales['clI_ID'].isin(df_trama['id'])]\n",
    "\n",
    "#Ordenar df_trama por fecha de venta , ID \n",
    "df_trama = df_trama.sort_values(by=['fechavta', 'id'], ascending=[True, False])\n",
    "\n",
    "# Calcular el rango para NRO_UNICO_CARGA\n",
    "nro_unico_carga_range = range(ultimo_codigo + 1, ultimo_codigo + 1 + len(df_trama))\n",
    "\n",
    "\n",
    "#Formatear columnas y ordenarlas\n",
    "trama = pd.DataFrame({\n",
    "    'ITEMS': '',\n",
    "    'NRO_UNICO_CARGA' : list(nro_unico_carga_range),\n",
    "    'FEC_VENTA': pd.to_datetime(df_trama['fechavta'], errors='coerce').dt.strftime('%d/%m/%Y'),\n",
    "    'TIPO_ASEG' : 'AT',\n",
    "    'PARENTESCO_ID': '125',\n",
    "    'TIPO_DOC_ID' : '317',\n",
    "    'NRO_DOC' : df_trama['dni'].astype(str).str.zfill(8), \n",
    "    'APE_PATERNO' : df_trama['apellido_paterno'].str.strip().str.upper(),\n",
    "    'APE_MATERNO' : df_trama['apellido_materno'].str.strip().str.upper(),\n",
    "    'PRIMER_NOMBRE' : df_trama['nombre1'].str.strip().str.upper(),\n",
    "    'SEGUNDO_NOMBRE' : df_trama['nombre2'].str.strip().str.upper(),\n",
    "    'FEC_NACIMIENTO' : df_trama['fechanacimiento'],\n",
    "    'SEXO_ID' : df_trama['sexo'].map({'m': '120', 'f': '121'}),\n",
    "    'ESTADO_CIVIL_ID' : '3',\n",
    "    'EMAIL' : df_trama['email'].str.strip(),\n",
    "    'TELEFONO_MOVIL' : df_trama['ceL1'].astype(str),\n",
    "    'PARTICIPACION' : '',\n",
    "    'PROFESION_ID' : '228',\n",
    "    'ACTIVIDAD_ID' : '507',\n",
    "    'CATEGORIA_ID' : '1899',\n",
    "    'DEPARTAMENTO': df_trama['DEPARTAMENTO_ID'],\n",
    "    'PROVINCIA': df_trama['PROVINCIA_ID'],\n",
    "    'DISTRITO': df_trama['DISTRITO_ID'],\n",
    "    'DIRECCION': df_trama['direccion'].str.strip(),\n",
    "    'PRIMA' : df_trama['PRIMA'],\n",
    "    'PRODUCTO_ID' : df_trama['PRODUCT_ID'],\n",
    "    'PRODUCTO' : df_trama['PRODUCTO'],\n",
    "    'PLAN_ID' : df_trama['PLAN_ID'],\n",
    "    'MONEDA_ID' : '545',\n",
    "    'FRECUENCIA_PAGO_ID' : '30',\n",
    "    'FORMA_PAGO_ID' : '192',\n",
    "    'TIPO_TARJETA_ID' : '',\n",
    "    'NRO_TARJETA' : '9999999999999999',\n",
    "    'FEC_EXP_TARJETA' : '01/2030',\n",
    "    'NRO_CUOTAS'   : '1',\n",
    "    'COD_VENDEDOR' : '99999',\n",
    "    'SUCURSAL_ID' : '38',\n",
    "    'CANAL_VENTA_ID' : '7',\n",
    "    'DPS' : '', \n",
    "    'FLG_POLIZA_ELECTRONICA' : 'S',\n",
    "    'OBSERVACION' : '',\n",
    "    'CODIGO_CLIENTE' : df_trama['id'],\n",
    "    'TipoPlan': df_trama['tipoContrato']})\n",
    "\n",
    "trama_adicionales = pd.DataFrame({\n",
    "    'ITEMS': '',\n",
    "    'NRO_UNICO_CARGA' : '',\n",
    "    'TIPO_ASEG' : df_adicionales['parentescO_ID'].str.strip().apply(mapear_tipo_aseg),\n",
    "    'PARENTESCO_ID': df_adicionales['parentescO_ID'].str.strip().apply(mapear_parentesco_id),\n",
    "    'TIPO_DOC_ID' : '317',\n",
    "    'NRO_DOC' : df_adicionales['nrO_DOC'].astype(str).str.zfill(8), \n",
    "    'APE_PATERNO' : df_adicionales['apE_PATERNO'].str.strip().str.upper(),\n",
    "    'APE_MATERNO' : df_adicionales['apE_MATERNO'].str.strip().str.upper(),\n",
    "    'PRIMER_NOMBRE' : df_adicionales['clI_ANOMBRE1'].str.strip().str.upper(),\n",
    "    'SEGUNDO_NOMBRE' : df_adicionales['clI_ANOMBRE2'].str.strip().str.upper(),\n",
    "    'FEC_NACIMIENTO' : df_adicionales['feC_NACIMIENTO'],\n",
    "    'SEXO_ID' : df_adicionales['clI_ANOMBRE1'].str.strip().str.title().apply(get_gender).map(lambda x: '121' if 'female' in x else ('120' if 'male' in x else '')),\n",
    "    'ESTADO_CIVIL_ID' : '3',\n",
    "    'EMAIL' : '',\n",
    "    'TELEFONO_MOVIL' : '',\n",
    "    'PARTICIPACION' : '',\n",
    "    'PROFESION_ID' : '228',\n",
    "    'ACTIVIDAD_ID' : '507',\n",
    "    'CATEGORIA_ID' : '1899',\n",
    "    'DEPARTAMENTO': '',\n",
    "    'PROVINCIA': '',\n",
    "    'DISTRITO': '',\n",
    "    'DIRECCION': '',\n",
    "    'PRIMA' : '',\n",
    "    'PRODUCTO_ID' : '',\n",
    "    'PRODUCTO' : '',\n",
    "    'PLAN_ID' : '',\n",
    "    'MONEDA_ID' : '545',\n",
    "    'FRECUENCIA_PAGO_ID' : '30',\n",
    "    'FORMA_PAGO_ID' : '192',\n",
    "    'TIPO_TARJETA_ID' : '',\n",
    "    'NRO_TARJETA' : '9999999999999999',\n",
    "    'FEC_EXP_TARJETA' : '01/2030',\n",
    "    'NRO_CUOTAS'   : '1',\n",
    "    'COD_VENDEDOR' : '99999',\n",
    "    'SUCURSAL_ID' : '38',\n",
    "    'CANAL_VENTA_ID' : '7',\n",
    "    'DPS' : '', \n",
    "    'FLG_POLIZA_ELECTRONICA' : 'S',\n",
    "    'OBSERVACION' : '',\n",
    "    'CODIGO_CLIENTE' : df_adicionales['clI_ID'],\n",
    "    'TipoPlan': 'Adicional'})\n",
    "\n",
    "#Cruzar trama_adicionales con df_trama para obtener FechaVenta\n",
    "trama_adicionales = trama_adicionales.merge(trama[['CODIGO_CLIENTE', 'FEC_VENTA']], left_on='CODIGO_CLIENTE', right_on='CODIGO_CLIENTE', how='left')\n",
    "\n",
    "# Combinar las tablas\n",
    "trama_completa = pd.concat([trama, trama_adicionales], ignore_index=True)\n",
    "\n",
    "# Añadir columna temporal para ordenamiento de TIPO_ASEG\n",
    "trama_completa['Orden_TIPO_ASEG'] = trama_completa['TIPO_ASEG'].map({'AT': 1, 'AH': 2})\n",
    "\n",
    "# Reordenar columnas por Fecha de Venta, CODIGO_CLIENTE y Tipo Asegurado\n",
    "trama_completa = trama_completa.sort_values(by=['CODIGO_CLIENTE','FEC_VENTA', 'Orden_TIPO_ASEG'], ascending=[True, True, True]).drop(columns=['Orden_TIPO_ASEG'])\n",
    "\n",
    "# Creamos una columna que marque donde comienza un nuevo grupo basado en 'TIPO_ASEG' siendo 'AT'\n",
    "trama_completa['grupo'] = (trama_completa['TIPO_ASEG'] == 'AT').cumsum()\n",
    "\n",
    "# Aplicamos el ffill solo dentro de cada grupo\n",
    "trama_completa = trama_completa.groupby(['CODIGO_CLIENTE', 'grupo'], group_keys=False).apply(lambda g: g.replace('', np.nan).ffill())\n",
    "\n",
    "# Eliminar la columna auxiliar 'grupo' si ya no es necesaria\n",
    "trama_completa = trama_completa.drop(columns=['grupo'])\n",
    "\n",
    "#Asignar indice a columna ITEMS en formato de texto en el orden actual\n",
    "trama_completa['ITEMS'] = range(1, len(trama_completa) + 1)\n",
    "\n",
    "\n",
    "# Aplicar la función a cada grupo y generar las observaciones\n",
    "observaciones_por_grupo = trama_completa.groupby('NRO_UNICO_CARGA').apply(generar_observaciones).reset_index()\n",
    "observaciones_por_grupo.columns = ['NRO_UNICO_CARGA', 'ERRORES']\n",
    "\n",
    "\n",
    "# Merge para asignar las observaciones al DataFrame original\n",
    "trama_completa = trama_completa.merge(observaciones_por_grupo, on='NRO_UNICO_CARGA', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el dataframe en un archivo excel CM_TLMK_V_ + hoy + .xlsx y en una hoja llamada 'Trama'\n",
    "trama_completa.to_excel(f'{Ruta}\\\\Tramas\\\\CM_TLMK_1_V_{hoy}.xlsx', sheet_name='Trama', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso terminado a las  20:30:35\n",
      "Ventas en Resultante igual a: 270\n",
      "Ventas en Validacion igual a: 260\n",
      "Ventas en Sumarizado igual a: 260\n"
     ]
    }
   ],
   "source": [
    "print(f'Proceso terminado a las ', dt.datetime.now().strftime('%H:%M:%S'))\n",
    "print(f'Ventas en Resultante igual a: {Ventas_resultantes}')\n",
    "print(f'Ventas en Validacion igual a: {df_validacion[\"Ventas_Adiciones\"].sum()}')\n",
    "print(f'Ventas en Sumarizado igual a: {sumarizado[\"Ventas_Adicionales\"].sum()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
